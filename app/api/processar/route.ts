import { NextResponse } from 'next/server';
import OpenAI from 'openai';
import { extrairTextoDoBuffer } from '@/lib/extrator';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, 
});

export async function POST(req: Request) {
  try {
    const { fileBase64, mimeType, servicos, textoLink } = await req.json();

    console.log("üß† Processando...", { servicos, mimeType });

    // --- MODO LINK ABNT (Mantido igual) ---
    if (servicos.includes('abnt_link')) {
        const promptLink = `Voc√™ √© um bibliotec√°rio especialista ABNT. Crie a refer√™ncia para: "${textoLink}". Retorne JSON: { "referencia": "..." }`;
        const completion = await openai.chat.completions.create({
            model: "gpt-3.5-turbo",
            messages: [{ role: "system", content: promptLink }],
            response_format: { type: "json_object" },
        });
        return NextResponse.json(JSON.parse(completion.choices[0].message.content || "{}"));
    }

    // --- PASSO CRUCIAL: EXTRA√á√ÉO DO TEXTO DO ARQUIVO ---
    let conteudoParaIA = "";
    
    // Se for Imagem, n√£o extra√≠mos texto (o GPT Vision v√™ a imagem)
    const ehImagem = mimeType && mimeType.startsWith('image/');
    
    if (!ehImagem && fileBase64) {
        // 1. Limpar o cabe√ßalho do base64 (ex: "data:application/pdf;base64,...")
        const base64Limpo = fileBase64.replace(/^data:.*;base64,/, "");
        
        // 2. Transformar em Buffer (Arquivo real na mem√≥ria)
        const buffer = Buffer.from(base64Limpo, 'base64');
        
        // 3. Extrair o texto usando nossa fun√ß√£o
        try {
            conteudoParaIA = await extrairTextoDoBuffer(buffer, mimeType);
            console.log("‚úÖ Texto extra√≠do com sucesso! Tamanho:", conteudoParaIA.length);
        } catch (e) {
            console.error("Erro ao extrair:", e);
            return NextResponse.json({ error: "Erro ao ler o arquivo. Certifique-se que o PDF cont√©m texto selecion√°vel." }, { status: 400 });
        }
    }

    // --- PREPARAR O PROMPT ---
    const systemPrompt = `
      Voc√™ √© um Tutor IA especialista.
      Baseie-se EXCLUSIVAMENTE no conte√∫do fornecido abaixo.
      
      FORMATO JSON OBRIGAT√ìRIO:
      {
        ${servicos.includes('resumo') ? '"resumo": "Resumo rico em HTML (<p>, <b>, <br>).",' : ''}
        ${servicos.includes('flashcards') ? '"flashcards": [{ "frente": "Pergunta curta?", "verso": "Resposta direta." }],' : ''}
        ${servicos.includes('questoes') ? `"questoes": [{ "enunciado": "...", "alternativas": ["A) ...", "B) ...", "C) ...", "D) ..."], "correta": 0, "explicacao": "..." }],` : ''}
        ${servicos.includes('mapa') ? '"mermaid": "graph TD; A[Conceito Central] --> B(Subconceito); B --> C{Detalhe}; style A fill:#f9f,stroke:#333;",' : ''}
        ${servicos.includes('podcast') ? '"podcast_script": "Ol√°! Vamos estudar este material. Come√ßando por...",' : ''}
        ${servicos.includes('apresentacao') ? '"roteiro_estruturado": { "introducao": "...", "desenvolvimento": "...", "conclusao": "..." }, "referencia_abnt_arquivo": "..." ' : ''}
      }
      
      DICAS:
      - Mapa Mental: Use n√≥s curtos. Deixe colorido.
      - Quest√µes: Crie perguntas desafiadoras sobre o texto lido.
      - Flashcards: Resuma conceitos chave.
    `;

    const messages: any[] = [{ role: "system", content: systemPrompt }];

    if (ehImagem) {
       // Se for imagem, manda o base64 direto pro Vision
       messages.push({
         role: "user",
         content: [
           { type: "text", text: "Analise esta imagem did√°tica e gere o conte√∫do pedido." },
           { type: "image_url", image_url: { url: fileBase64 } } 
         ]
       });
    } else {
       // Se for PDF, manda o TEXTO EXTRA√çDO
       if (conteudoParaIA.length < 50) {
           return NextResponse.json({ error: "O arquivo parece vazio ou √© uma imagem digitalizada sem texto (OCR necess√°rio)." }, { status: 400 });
       }
       messages.push({
         role: "user",
         content: `Conte√∫do do Arquivo para Estudo: \n"${conteudoParaIA}"` 
       });
    }

    console.log("üöÄ Enviando para OpenAI...");
    const completion = await openai.chat.completions.create({
      model: "gpt-4o", // Gpt-4o √© √≥timo para seguir JSON
      messages: messages,
      response_format: { type: "json_object" },
      temperature: 0.5,
    });

    const respostaTexto = completion.choices[0].message.content;
    const dadosProcessados = JSON.parse(respostaTexto || "{}");

    // --- GERAR PODCAST (√ÅUDIO) ---
    if (servicos.includes('podcast') && dadosProcessados.podcast_script) {
        console.log("üéôÔ∏è Gerando √°udio...");
        try {
            const mp3 = await openai.audio.speech.create({
                model: "tts-1",
                voice: "alloy",
                input: dadosProcessados.podcast_script.substring(0, 4096), // Limite de seguran√ßa
            });
            const buffer = Buffer.from(await mp3.arrayBuffer());
            dadosProcessados.audio_base64 = "data:audio/mp3;base64," + buffer.toString('base64');
        } catch (e) {
            console.error("Erro ao gerar √°udio:", e);
            // N√£o quebramos o resto se o √°udio falhar
        }
    }

    return NextResponse.json(dadosProcessados);

  } catch (error: any) {
    console.error('‚ùå ERRO GERAL:', error);
    return NextResponse.json({ error: 'Falha interna: ' + error.message }, { status: 500 });
  }
}